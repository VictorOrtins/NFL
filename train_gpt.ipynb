{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d4a443",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a2e05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 16:13:00.224959: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-02 16:13:00.264022: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-02 16:13:01.705037: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Dense, LayerNormalization, Dropout,\n",
    "                                     MultiHeadAttention, Layer)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856f1d41",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d1886",
   "metadata": {},
   "source": [
    "## Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebea1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, weeks, file_type='input'):\n",
    "    all_dfs = []\n",
    "    for week in weeks:\n",
    "        file_name = f\"{file_type}_2023_w{str(week).zfill(2)}.csv\"\n",
    "        file_path = os.path.join(base_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['week'] = week\n",
    "            all_dfs.append(df)\n",
    "    if not all_dfs: return pd.DataFrame()\n",
    "    return pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535597f7",
   "metadata": {},
   "source": [
    "## Feature Engineering Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6180e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_height_to_inches(height_str):\n",
    "    try:\n",
    "        feet, inches = map(int, str(height_str).split('-'))\n",
    "        return feet * 12 + inches\n",
    "    except: return np.nan\n",
    "\n",
    "def calculate_age(birth_date_str, current_date=datetime(2024, 1, 1)):\n",
    "    try:\n",
    "        birth_date = datetime.strptime(str(birth_date_str), '%Y-%m-%d')\n",
    "        return (current_date - birth_date).days / 365.25\n",
    "    except: return np.nan\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['player_height_inches'] = df['player_height'].apply(convert_height_to_inches)\n",
    "    df['player_age'] = df['player_birth_date'].apply(calculate_age)\n",
    "    df['dist_to_land_spot'] = np.sqrt((df['x'] - df['ball_land_x'])**2 + (df['y'] - df['ball_land_y'])**2)\n",
    "    df['delta_x_to_land'] = df['ball_land_x'] - df['x']\n",
    "    df['delta_y_to_land'] = df['ball_land_y'] - df['y']\n",
    "    dir_rad = np.deg2rad(df['dir'])\n",
    "    df['vx'] = df['s'] * np.cos(dir_rad)\n",
    "    df['vy'] = df['s'] * np.sin(dir_rad)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fca859",
   "metadata": {},
   "source": [
    "## Preprocessing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b872f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(input_df, output_df, features_to_use, max_input_len, max_output_len, is_test=False):\n",
    "    unique_plays = input_df[['game_id', 'play_id', 'nfl_id']].drop_duplicates()\n",
    "    \n",
    "    encoder_input_data = []\n",
    "    decoder_output_data = [] # Apenas para treino/validação\n",
    "    play_identifiers = [] # Para mapear previsões de volta\n",
    "\n",
    "    for _, row in unique_plays.iterrows():\n",
    "        game_id, play_id, nfl_id = row['game_id'], row['play_id'], row['nfl_id']\n",
    "        \n",
    "        input_seq = input_df[(input_df['game_id'] == game_id) & (input_df['play_id'] == play_id) & (input_df['nfl_id'] == nfl_id)]\n",
    "        input_features = input_seq[features_to_use].values\n",
    "        \n",
    "        padded_input = np.zeros((max_input_len, len(features_to_use)))\n",
    "        seq_len = min(len(input_features), max_input_len)\n",
    "        padded_input[-seq_len:] = input_features[-seq_len:]\n",
    "        encoder_input_data.append(padded_input)\n",
    "        play_identifiers.append((game_id, play_id, nfl_id, input_seq['num_frames_output'].iloc[0]))\n",
    "        \n",
    "        if not is_test:\n",
    "            output_seq = output_df[(output_df['game_id'] == game_id) & (output_df['play_id'] == play_id) & (output_df['nfl_id'] == nfl_id)]\n",
    "            output_coords = output_seq[['x', 'y']].values\n",
    "            \n",
    "            padded_output = np.zeros((max_output_len, 2))\n",
    "            seq_len_out = min(len(output_coords), max_output_len)\n",
    "            if seq_len_out > 0:\n",
    "                padded_output[:seq_len_out] = output_coords[:seq_len_out]\n",
    "            decoder_output_data.append(padded_output)\n",
    "\n",
    "    if is_test:\n",
    "        return np.array(encoder_input_data), play_identifiers\n",
    "    else:\n",
    "        return np.array(encoder_input_data), np.array(decoder_output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266bda60",
   "metadata": {},
   "source": [
    "## Model Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f914dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(Layer):\n",
    "    \"\"\"\n",
    "    Injeta informação sobre a posição relativa ou absoluta dos tokens na sequência.\n",
    "    \"\"\"\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model\n",
    "        )\n",
    "        # aplica seno nos índices pares\n",
    "        angle_rads_even = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # aplica cosseno nos índices ímpares\n",
    "        angle_rads_odd = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([angle_rads_even, angle_rads_odd], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7eddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = Input(shape=(None, d_model), name=\"inputs\")\n",
    "    \n",
    "    # Multi-Head Attention\n",
    "    attention = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=d_model, name=\"attention\")(inputs, inputs)\n",
    "    attention = Dropout(dropout)(attention)\n",
    "    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    outputs = Dense(units=units, activation=\"relu\")(attention)\n",
    "    outputs = Dense(units=d_model)(outputs)\n",
    "    outputs = Dropout(dropout)(outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ffdc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "    # Masked Multi-Head Attention (Self-Attention)\n",
    "    attention1 = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=d_model, name=\"attention_1\")(inputs, inputs, use_causal_mask=True)\n",
    "    attention1 = LayerNormalization(epsilon=1e-6)(inputs + attention1)\n",
    "    \n",
    "    # Multi-Head Attention (Cross-Attention)\n",
    "    attention2 = MultiHeadAttention(\n",
    "        num_heads=num_heads, key_dim=d_model, name=\"attention_2\")(attention1, enc_outputs)\n",
    "    attention2 = Dropout(dropout)(attention2)\n",
    "    attention2 = LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
    "\n",
    "    # Feed Forward Network\n",
    "    outputs = Dense(units=units, activation=\"relu\")(attention2)\n",
    "    outputs = Dense(units=d_model)(outputs)\n",
    "    outputs = Dropout(dropout)(outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(attention2 + outputs)\n",
    "\n",
    "    return Model(inputs=[inputs, enc_outputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b653a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_model(input_vocab_size, target_vocab_size, max_seq_len, d_model=128, num_heads=8,\n",
    "                            num_encoder_layers=4, num_decoder_layers=4, dff=512, dropout=0.1):\n",
    "    \"\"\"Constrói o modelo Transformer Encoder-Decoder completo.\"\"\"\n",
    "    \n",
    "    # --- Inputs ---\n",
    "    encoder_inputs = Input(shape=(None, input_vocab_size), name=\"encoder_inputs\")\n",
    "    decoder_inputs = Input(shape=(None, target_vocab_size), name=\"decoder_inputs\")\n",
    "\n",
    "    # --- Embeddings + Positional Encoding ---\n",
    "    encoder_embedding = Dense(d_model, name=\"encoder_embedding\")(encoder_inputs)\n",
    "    encoder_embedding = PositionalEncoding(max_seq_len, d_model)(encoder_embedding)\n",
    "    \n",
    "    decoder_embedding = Dense(d_model, name=\"decoder_embedding\")(decoder_inputs)\n",
    "    decoder_embedding = PositionalEncoding(max_seq_len, d_model)(decoder_embedding)\n",
    "\n",
    "    # --- Encoder ---\n",
    "    enc_outputs = Dropout(dropout)(encoder_embedding)\n",
    "    for i in range(num_encoder_layers):\n",
    "        enc_outputs = transformer_encoder_layer(dff, d_model, num_heads, dropout, name=f\"encoder_layer_{i}\")(enc_outputs)\n",
    "\n",
    "    # --- Decoder ---\n",
    "    dec_outputs = Dropout(dropout)(decoder_embedding)\n",
    "    for i in range(num_decoder_layers):\n",
    "        dec_outputs = transformer_decoder_layer(dff, d_model, num_heads, dropout, name=f\"decoder_layer_{i}\")([dec_outputs, enc_outputs])\n",
    "    \n",
    "    # --- Output Layer ---\n",
    "    final_output = Dense(target_vocab_size, name=\"final_output\")(dec_outputs)\n",
    "\n",
    "    return Model(inputs=[encoder_inputs, decoder_inputs], outputs=final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33b01f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_pipeline(config):\n",
    "    \"\"\"Função principal que encapsula todo o processo de treinamento.\"\"\"\n",
    "    \n",
    "    PROCESSED_DATA_PATH = 'processed_training_data.npz'\n",
    "\n",
    "    # --- LÓGICA DE CARREGAMENTO ---\n",
    "    # Verifica se os dados processados já existem\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        print(\"Dados pré-processados não encontrados. Executando o pipeline completo...\")\n",
    "        # --- Carregamento de TODOS os dados de treino ---\n",
    "        print(\"Carregando dados de treinamento (Semanas 1-18)...\")\n",
    "        input_df = load_data(config['BASE_PATH'], range(1, 19), 'input')\n",
    "        output_df = load_data(config['BASE_PATH'], range(1, 19), 'output')\n",
    "        \n",
    "        # --- Engenharia de Atributos ---\n",
    "        print(\"Executando engenharia de atributos...\")\n",
    "        input_df = feature_engineering(input_df)\n",
    "\n",
    "        # --- Definição do Pré-processador ---\n",
    "        numeric_features = ['x', 'y', 's', 'a', 'player_height_inches', 'player_age', 'dist_to_land_spot', 'delta_x_to_land', 'delta_y_to_land', 'vx', 'vy']\n",
    "        categorical_features = ['play_direction', 'player_position', 'player_side', 'player_role']\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "            ], remainder='drop'\n",
    "        )\n",
    "        \n",
    "        # --- Divisão Treino/Validação por semana ---\n",
    "        train_df = input_df[input_df['week'].isin(config['TRAIN_WEEKS'])]\n",
    "        val_df = input_df[input_df['week'].isin(config['VALIDATION_WEEKS'])]\n",
    "        \n",
    "        # AJUSTAR ('fit') o preprocessor APENAS nos dados de treino\n",
    "        print(\"Ajustando o pré-processador nos dados de treino...\")\n",
    "        preprocessor.fit(train_df[numeric_features + categorical_features])\n",
    "        \n",
    "        # Salvar o preprocessor para uso na inferência\n",
    "        joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "        \n",
    "        # Aplicar a transformação\n",
    "        processed_train_data = preprocessor.transform(train_df[numeric_features + categorical_features])\n",
    "        processed_val_data = preprocessor.transform(val_df[numeric_features + categorical_features])\n",
    "        \n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        \n",
    "        processed_train_df = pd.DataFrame(processed_train_data, columns=feature_names, index=train_df.index)\n",
    "        processed_val_df = pd.DataFrame(processed_val_data, columns=feature_names, index=val_df.index)\n",
    "        \n",
    "        id_cols = ['game_id', 'play_id', 'nfl_id', 'num_frames_output']\n",
    "        final_train_df = pd.concat([train_df[id_cols], processed_train_df], axis=1)\n",
    "        final_val_df = pd.concat([val_df[id_cols], processed_val_df], axis=1)\n",
    "\n",
    "        # --- Criação de Sequências ---\n",
    "        print(\"Criando sequências de treino e validação...\")\n",
    "        X_enc_train, y_dec_train = create_sequences(final_train_df, output_df, feature_names, config['MAX_INPUT_LEN'], config['MAX_OUTPUT_LEN'])\n",
    "        X_enc_val, y_dec_val = create_sequences(final_val_df, output_df, feature_names, config['MAX_INPUT_LEN'], config['MAX_OUTPUT_LEN'])\n",
    "\n",
    "        print(f\"Salvando dados pré-processados em '{PROCESSED_DATA_PATH}'...\")\n",
    "        np.savez_compressed(\n",
    "            PROCESSED_DATA_PATH,\n",
    "            X_enc_train=X_enc_train,\n",
    "            y_dec_train=y_dec_train,\n",
    "            X_enc_val=X_enc_val,\n",
    "            y_dec_val=y_dec_val\n",
    "        )\n",
    "        print(\"Dados salvos com sucesso para uso futuro.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Carregando dados pré-processados de '{PROCESSED_DATA_PATH}'...\")\n",
    "        processed_data = np.load(PROCESSED_DATA_PATH)\n",
    "        X_enc_train = processed_data['X_enc_train']\n",
    "        y_dec_train = processed_data['y_dec_train']\n",
    "        X_enc_val = processed_data['X_enc_val']\n",
    "        y_dec_val = processed_data['y_dec_val']\n",
    "        print(\"Dados carregados com sucesso.\") \n",
    "    \n",
    "    # Input do decoder para teacher forcing\n",
    "    dec_input_train = np.zeros_like(y_dec_train); dec_input_train[:, 1:, :] = y_dec_train[:, :-1, :]\n",
    "    dec_input_val = np.zeros_like(y_dec_val); dec_input_val[:, 1:, :] = y_dec_val[:, :-1, :]\n",
    "\n",
    "    # --- Construção e Compilação do Modelo ---\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    input_vocab_size = X_enc_train.shape[-1] # Número de features de entrada\n",
    "    target_vocab_size = y_dec_train.shape[-1] # Número de features de saída (2, para x e y)\n",
    "    max_seq_len = max(X_enc_train.shape[1], y_dec_train.shape[1])\n",
    "\n",
    "    model = build_transformer_model(\n",
    "        input_vocab_size=input_vocab_size,\n",
    "        target_vocab_size=target_vocab_size,\n",
    "        max_seq_len=max_seq_len,\n",
    "        d_model=config['D_MODEL'],\n",
    "        num_heads=config['NUM_HEADS'],\n",
    "        dff=config['DFF']\n",
    "    )\n",
    "    \n",
    "    optimizer = Adam(learning_rate=config['LEARNING_RATE'], beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    model.summary()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5)\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nIniciando o treinamento do modelo Transformer...\")\n",
    "    history = model.fit(\n",
    "        [X_enc_train, dec_input_train], y_dec_train,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        epochs=config['EPOCHS'],\n",
    "        validation_data=([X_enc_val, dec_input_val], y_dec_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    model.save('transformer_model.h5')\n",
    "    print(\"Treinamento concluído e modelo salvo como 'transformer_model.h5'\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46a4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_for_grid_search(config, X_enc_train, y_dec_train, X_enc_val, y_dec_val):\n",
    "    \"\"\"\n",
    "    Função adaptada para rodar um único treinamento dentro do Grid Search.\n",
    "    Ela constrói, compila e treina o modelo, retornando o melhor resultado.\n",
    "    \"\"\"\n",
    "    # Limpa a sessão do Keras para garantir que os modelos não interfiram uns com os outros\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # --- Construção e Compilação do Modelo ---\n",
    "    input_shape = X_enc_train.shape[1:]\n",
    "    model = build_seq2seq_model(\n",
    "        input_shape, \n",
    "        config['MAX_OUTPUT_LEN'], \n",
    "        latent_dim=config['LATENT_DIM'],\n",
    "        dropout_rate=config['DROPOUT_RATE']\n",
    "    )\n",
    "    \n",
    "    optimizer = Adam(learning_rate=config['LEARNING_RATE'])\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    # --- Preparação dos Dados do Decoder ---\n",
    "    dec_input_train = np.zeros_like(y_dec_train); dec_input_train[:, 1:, :] = y_dec_train[:, :-1, :]\n",
    "    dec_input_val = np.zeros_like(y_dec_val); dec_input_val[:, 1:, :] = y_dec_val[:, :-1, :]\n",
    "    \n",
    "    # --- Treinamento ---\n",
    "    # Usamos EarlyStopping para parar o treino quando a perda de validação não melhora\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n--- Treinando com config: {config} ---\")\n",
    "    history = model.fit(\n",
    "        [X_enc_train, dec_input_train], y_dec_train,\n",
    "        batch_size=config['BATCH_SIZE'],\n",
    "        epochs=config['EPOCHS'],\n",
    "        validation_data=([X_enc_val, dec_input_val], y_dec_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1 # Mudar para 0 ou 2 se quiser menos output\n",
    "    )\n",
    "    \n",
    "    # Retorna a melhor pontuação de perda de validação encontrada durante o treino\n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "    return best_val_loss, history\n",
    "\n",
    "\n",
    "# --- NOVA FUNÇÃO MESTRE PARA O GRID SEARCH ---\n",
    "\n",
    "def run_grid_search(param_grid, epochs=100):\n",
    "    \"\"\"\n",
    "    Orquestra o processo de Grid Search.\n",
    "    \"\"\"\n",
    "    # --- 1. Definir o Espaço de Busca de Hiperparâmetros ---\n",
    "   \n",
    "\n",
    "    # --- 2. Carregar e Preparar os Dados (apenas uma vez) ---\n",
    "    # Esta parte é a mesma do script anterior, carregando os dados do arquivo .npz\n",
    "    PROCESSED_DATA_PATH = 'processed_training_data.npz'\n",
    "    if not os.path.exists(PROCESSED_DATA_PATH):\n",
    "        print(\"Erro: Arquivo de dados pré-processados não encontrado. Rode o pipeline de treinamento normal primeiro.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Carregando dados pré-processados de '{PROCESSED_DATA_PATH}'...\")\n",
    "    processed_data = np.load(PROCESSED_DATA_PATH)\n",
    "    X_enc_train = processed_data['X_enc_train']\n",
    "    y_dec_train = processed_data['y_dec_train']\n",
    "    X_enc_val = processed_data['X_enc_val']\n",
    "    y_dec_val = processed_data['y_dec_val']\n",
    "    print(\"Dados carregados com sucesso.\")\n",
    "\n",
    "    # --- 3. Iterar sobre as Combinações de Parâmetros ---\n",
    "    results = []\n",
    "    \n",
    "    # Gera todas as combinações de parâmetros\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    print(f\"\\nIniciando Grid Search com {len(param_combinations)} combinações.\")\n",
    "\n",
    "    for i, params in enumerate(param_combinations):\n",
    "        print(f\"\\n--- Rodada {i+1}/{len(param_combinations)} ---\")\n",
    "        \n",
    "        # Cria a config para esta rodada\n",
    "        current_config = {\n",
    "            'MAX_OUTPUT_LEN': 40, # Valor fixo, pode ser adicionado ao grid se desejar\n",
    "            'EPOCHS': epochs, # Um número alto, pois o EarlyStopping irá parar antes\n",
    "            **params # Adiciona os parâmetros da rodada atual\n",
    "        }\n",
    "        \n",
    "        # Roda o treinamento e obtém a pontuação\n",
    "        validation_score, history = run_training_for_grid_search(\n",
    "            current_config, X_enc_train, y_dec_train, X_enc_val, y_dec_val\n",
    "        )\n",
    "        \n",
    "        # Salva o resultado\n",
    "        results.append({\n",
    "            'score': validation_score,\n",
    "            'history': history,\n",
    "            **params\n",
    "        })\n",
    "\n",
    "    # --- 4. Exibir os Melhores Resultados ---\n",
    "    print(\"\\n--- Grid Search Concluído ---\")\n",
    "    \n",
    "    # Converte os resultados para um DataFrame para fácil visualização\n",
    "    results_df = pd.DataFrame(results).sort_values(by='score', ascending=True)\n",
    "    \n",
    "    print(\"Melhores combinações de hiperparâmetros (ordenado pela menor perda de validação):\")\n",
    "    print(results_df)\n",
    "\n",
    "    # Salva os resultados em um CSV\n",
    "    results_df.to_csv('grid_search_results.csv', index=False)\n",
    "    print(\"\\nResultados do Grid Search salvos em 'grid_search_results.csv'\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6f3d8",
   "metadata": {},
   "source": [
    "## Submission Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1eb7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_format_submission(config):\n",
    "    \"\"\"Carrega os dados de teste, aplica o pipeline e gera a submissão.\"\"\"\n",
    "    print(\"\\nIniciando pipeline de inferência...\")\n",
    "\n",
    "    PROCESSED_TEST_PATH_NPZ = 'processed_test_data.npz'\n",
    "    PROCESSED_TEST_PATH_PKL = 'play_identifiers.pkl'\n",
    "    \n",
    "    if not os.path.exists(PROCESSED_TEST_PATH_NPZ) and os.path.exists(PROCESSED_TEST_PATH_PKL):\n",
    "        # --- Carregar Dados de Teste e Modelos ---\n",
    "        test_input_df = pd.read_csv(os.path.join(config['BASE_PATH'], 'test_input.csv'))\n",
    "        # O arquivo 'test.csv' contém os IDs que precisam ser previstos, útil para validação do formato\n",
    "        test_ids_df = pd.read_csv(os.path.join(config['BASE_PATH'], 'test.csv'))\n",
    "\n",
    "        encoder_model = tf.keras.models.load_model('encoder_model.h5')\n",
    "        decoder_model = tf.keras.models.load_model('decoder_model.h5')\n",
    "        preprocessor = joblib.load('preprocessor.joblib')\n",
    "\n",
    "        # --- Pré-processamento e Engenharia de Atributos ---\n",
    "        test_input_df = feature_engineering(test_input_df)\n",
    "        \n",
    "        numeric_features = ['x', 'y', 's', 'a', 'player_height_inches', 'player_age', 'dist_to_land_spot', 'delta_x_to_land', 'delta_y_to_land', 'vx', 'vy']\n",
    "        categorical_features = ['play_direction', 'player_position', 'player_side', 'player_role']\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "        \n",
    "        # Aplicar o pré-processador JÁ AJUSTADO\n",
    "        processed_test_data = preprocessor.transform(test_input_df[numeric_features + categorical_features])\n",
    "        processed_test_df = pd.DataFrame(processed_test_data, columns=feature_names, index=test_input_df.index)\n",
    "        \n",
    "        id_cols = ['game_id', 'play_id', 'nfl_id', 'num_frames_output']\n",
    "        final_test_df = pd.concat([test_input_df[id_cols], processed_test_df], axis=1)\n",
    "\n",
    "        # --- Criar Sequências de Teste ---\n",
    "        X_enc_test, play_identifiers = create_sequences(final_test_df, None, feature_names, config['MAX_INPUT_LEN'], config['MAX_OUTPUT_LEN'], is_test=True)\n",
    "        \n",
    "        print(\"Salvando dados de teste pré-processados...\")\n",
    "        np.savez_compressed(PROCESSED_TEST_PATH_NPZ, X_enc_test=X_enc_test)\n",
    "        with open(PROCESSED_TEST_PATH_PKL, 'wb') as f:\n",
    "            joblib.dump(play_identifiers, f)\n",
    "    else:\n",
    "        print(\"Carregando dados de teste pré-processados do disco...\")\n",
    "        processed_data = np.load(PROCESSED_TEST_PATH_NPZ)\n",
    "        X_enc_test = processed_data['X_enc_test']\n",
    "        \n",
    "        with open(PROCESSED_TEST_PATH_PKL, 'rb') as f:\n",
    "            play_identifiers = joblib.load(f)\n",
    "\n",
    "    # --- Gerar Previsões (Loop de Inferência) ---\n",
    "    predictions = []\n",
    "    for i in range(len(X_enc_test)):\n",
    "        input_seq = X_enc_test[i:i+1]\n",
    "        states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, 2)) # Começa com (0,0)\n",
    "        \n",
    "        num_frames_to_predict = play_identifiers[i][3]\n",
    "        output_sequence = []\n",
    "\n",
    "        for _ in range(num_frames_to_predict):\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "            output_sequence.append(output_tokens[0, 0, :])\n",
    "            target_seq = output_tokens\n",
    "            states_value = [h, c]\n",
    "        \n",
    "        predictions.append(output_sequence)\n",
    "        \n",
    "    # --- Formatar para Submissão ---\n",
    "    submission_rows = []\n",
    "    for i, play_info in enumerate(play_identifiers):\n",
    "        game_id, play_id, nfl_id, num_frames = play_info\n",
    "        predicted_trajectory = predictions[i]\n",
    "        for frame_idx, coords in enumerate(predicted_trajectory):\n",
    "            frame_id = frame_idx + 1\n",
    "            row_id = f\"{game_id}_{play_id}_{nfl_id}_{frame_id}\"\n",
    "            submission_rows.append({'id': row_id, 'x': coords[0], 'y': coords[1]})\n",
    "\n",
    "    submission_df = pd.DataFrame(submission_rows)\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    print(f\"Arquivo 'submission.csv' gerado com {len(submission_df)} linhas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a1f2c5",
   "metadata": {},
   "source": [
    "## Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac549cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plota os gráficos de perda e RMSE do treinamento e validação.\n",
    "    \n",
    "    Args:\n",
    "        history: O objeto history retornado pelo model.fit() do Keras.\n",
    "    \"\"\"\n",
    "    # Dados de Perda (Loss - Mean Squared Error)\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    # Dados da Métrica (Root Mean Squared Error)\n",
    "    rmse = history.history['root_mean_squared_error']\n",
    "    val_rmse = history.history['val_root_mean_squared_error']\n",
    "    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    # Criar a figura com dois subplots (um para Loss, um para RMSE)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plotar o gráfico de Perda (Loss)\n",
    "    ax1.plot(epochs, loss, 'bo-', label='Perda de Treinamento')\n",
    "    ax1.plot(epochs, val_loss, 'ro-', label='Perda de Validação')\n",
    "    ax1.set_title('Perda (MSE) de Treinamento e Validação')\n",
    "    ax1.set_xlabel('Épocas')\n",
    "    ax1.set_ylabel('Perda (MSE)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plotar o gráfico da Métrica (RMSE)\n",
    "    ax2.plot(epochs, rmse, 'bo-', label='RMSE de Treinamento')\n",
    "    ax2.plot(epochs, val_rmse, 'ro-', label='RMSE de Validação')\n",
    "    ax2.set_title('Métrica (RMSE) de Treinamento e Validação')\n",
    "    ax2.set_xlabel('Épocas')\n",
    "    ax2.set_ylabel('RMSE')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png') # Salva a imagem em um arquivo\n",
    "    print(\"Gráfico do histórico de treinamento salvo como 'training_history.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0070f15a",
   "metadata": {},
   "source": [
    "# Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d24fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados pré-processados de 'processed_training_data.npz'...\n",
      "Dados carregados com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759432385.849074   14337 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 751 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_0     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,192</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,192</span> │ encoder_layer_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_embeddin… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEncodin…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,192</span> │ encoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ positional_encod… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">22,192</span> │ encoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_0     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,768</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,768</span> │ decoder_layer_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,768</span> │ decoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,768</span> │ decoder_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ encoder_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │ decoder_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │        \u001b[38;5;34m864\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encoding │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ encoder_embeddin… │\n",
       "│ (\u001b[38;5;33mPositionalEncodin…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ positional_encod… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_0     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m22,192\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │         \u001b[38;5;34m72\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m22,192\u001b[0m │ encoder_layer_0[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_encodin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ decoder_embeddin… │\n",
       "│ (\u001b[38;5;33mPositionalEncodin…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m22,192\u001b[0m │ encoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ positional_encod… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_layer_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m22,192\u001b[0m │ encoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_0     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m31,768\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder_layer_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m31,768\u001b[0m │ decoder_layer_0[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder_layer_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m31,768\u001b[0m │ decoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder_layer_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_layer_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │     \u001b[38;5;34m31,768\u001b[0m │ decoder_layer_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ encoder_layer_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)   │         \u001b[38;5;34m50\u001b[0m │ decoder_layer_3[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,826</span> (846.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m216,826\u001b[0m (846.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,826</span> (846.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,826\u001b[0m (846.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando o treinamento do modelo Transformer...\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 16:13:23.747056: I external/local_xla/xla/service/service.cc:163] XLA service 0x783cc0013100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-02 16:13:23.747077: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2025-10-02 16:13:24.285352: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-02 16:13:27.072806: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301\n",
      "2025-10-02 16:13:29.396058: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 16.01MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-02 16:13:29.462285: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at xla_ops.cc:590 : RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16784896 bytes. [tf-allocator-allocation-error='']\n",
      "2025-10-02 16:13:29.462356: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 16784896 bytes.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      " [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_14337/1329281698.py\", line 10, in <module>\n\n  File \"/tmp/ipykernel_14337/1199820286.py\", line 108, in run_training_pipeline\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nOut of memory while trying to allocate 16784896 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_36699]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhaustedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m config_transformer = {\n\u001b[32m      2\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mBATCH_SIZE\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m      3\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEPOCHS\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m20\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mDFF\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m256\u001b[39m,      \u001b[38;5;66;03m# Dimensão da camada Feed-Forward interna\u001b[39;00m\n\u001b[32m      8\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model, history = \u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_transformer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mrun_training_pipeline\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    102\u001b[39m callbacks = [\n\u001b[32m    103\u001b[39m     EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m10\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    104\u001b[39m     ReduceLROnPlateau(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, factor=\u001b[32m0.2\u001b[39m, patience=\u001b[32m5\u001b[39m)\n\u001b[32m    105\u001b[39m ]\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIniciando o treinamento do modelo Transformer...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_enc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_input_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dec_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mBATCH_SIZE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEPOCHS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_enc_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_input_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dec_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m model.save(\u001b[33m'\u001b[39m\u001b[33mtransformer_model.h5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTreinamento concluído e modelo salvo como \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtransformer_model.h5\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nfl/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mResourceExhaustedError\u001b[39m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/base_events.py\", line 604, in run_forever\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/asyncio/events.py\", line 80, in _run\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_14337/1329281698.py\", line 10, in <module>\n\n  File \"/tmp/ipykernel_14337/1199820286.py\", line 108, in run_training_pipeline\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/victor/anaconda3/envs/nfl/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\nOut of memory while trying to allocate 16784896 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_multi_step_on_iterator_36699]"
     ]
    }
   ],
   "source": [
    "config_transformer = {\n",
    "        'BATCH_SIZE': 2,\n",
    "        'EPOCHS': 20,\n",
    "        'LEARNING_RATE': 0.0005,\n",
    "        'D_MODEL': 24,   # Dimensão do modelo (tem que ser divisível por NUM_HEADS)\n",
    "        'NUM_HEADS': 4,  # Número de cabeças de atenção\n",
    "        'DFF': 256,      # Dimensão da camada Feed-Forward interna\n",
    "    }\n",
    "\n",
    "model, history = run_training_pipeline(config_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_transformer(config, model):\n",
    "    \"\"\"Gera previsões e o arquivo de submissão usando o modelo Transformer.\"\"\"\n",
    "    \n",
    "    # ... [COLE AQUI A LÓGICA PARA CARREGAR E PROCESSAR OS DADOS DE TESTE] ...\n",
    "    # O resultado deve ser: X_enc_test, play_identifiers\n",
    "\n",
    "    print(\"Iniciando previsões com o modelo Transformer...\")\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(len(X_enc_test)):\n",
    "        input_seq = X_enc_test[i:i+1]\n",
    "        \n",
    "        # Inicia o decoder com um token de 'start' (um único passo de tempo com zeros)\n",
    "        decoder_input = np.zeros((1, 1, 2)) # (batch, seq_len, features)\n",
    "        \n",
    "        num_frames_to_predict = play_identifiers[i][3]\n",
    "        \n",
    "        for _ in range(num_frames_to_predict):\n",
    "            # Faz a previsão\n",
    "            pred = model.predict([input_seq, decoder_input], verbose=0)\n",
    "            \n",
    "            # Pega o último ponto previsto\n",
    "            next_coord = pred[:, -1:, :] # Pega o último passo da sequência\n",
    "            \n",
    "            # Concatena o ponto previsto à entrada do decoder para a próxima iteração\n",
    "            decoder_input = tf.concat([decoder_input, next_coord], axis=1)\n",
    "\n",
    "        # A saída final é a sequência gerada pelo decoder (ignorando o token de start)\n",
    "        output_sequence = decoder_input.numpy()[0, 1:, :]\n",
    "        predictions.append(output_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6416b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
